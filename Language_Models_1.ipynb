{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "OsV6sILlovc_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsV6sILlovc_",
        "outputId": "79d5f1e7-8e35-4687-ca37-2eacb7e2e1e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]   Package cess_cat is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('cess_cat')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e662c74",
      "metadata": {
        "id": "1e662c74"
      },
      "source": [
        "Load a corpus in Catalan or English. The nltk corpora result from tokenizing and segmenting into sentences large collections of text.\n",
        "\n",
        "The ``gutenberg`` corpus comes from a set of English literature classics. The ``cess_cat`` corpus comes from https://www.cs.upc.edu/~nlp/wikicorpus/, the \"120 Million Word Spanish Corpus\" which has a subset in Catalan of 50 million words scrapped from Vikipedia in 2006."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "1525dd55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1525dd55",
        "outputId": "850301ea-593d-4375-eafd-2f258b36160f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
            "corpus gutenberg : 2621613 words, 98552 sentences\n"
          ]
        }
      ],
      "source": [
        "name_corpus = 'gutenberg'\n",
        "\n",
        "if name_corpus=='cess_cat':\n",
        "    from nltk.corpus import cess_cat as corpus\n",
        "    # clean the corpus of strange words\n",
        "    words = []\n",
        "    words_to_remove = ['*0*', '-Fpa-', '-Fpt-']\n",
        "    for w in tqdm(corpus.words()):\n",
        "        if w not in words_to_remove:\n",
        "            words.append(w)\n",
        "\n",
        "elif name_corpus=='gutenberg':\n",
        "    from nltk.corpus import gutenberg as corpus\n",
        "    print(corpus.fileids())\n",
        "    words = corpus.words()\n",
        "else:\n",
        "    assert False\n",
        "\n",
        "print('corpus {} : {} words, {} sentences'\n",
        "      .format(name_corpus, len(words), len(corpus.sents())))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd42b3ec",
      "metadata": {
        "id": "cd42b3ec"
      },
      "source": [
        "Build a language model from bigrams. A LM is just a dictionary\n",
        "with key = condition = one word, and value = ``FreqDist``\n",
        "object = another dictionary with key = next word, value = number\n",
        "of occurrences.\n",
        "This is adapted from https://www.nltk.org/book/ch02.html, section 2.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ba30c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ba30c3",
        "outputId": "58a725df-af21-46f0-b105-a69d3c69f929"
      },
      "outputs": [],
      "source": [
        "grams = list(nltk.bigrams(words))\n",
        "# also trigrams, ngrams, everygrams(max_len)\n",
        "cfd = nltk.ConditionalFreqDist(grams)\n",
        "print(cfd.conditions())\n",
        "for i in [100, 200, 300, 400]:\n",
        "    print(cfd.conditions()[i])\n",
        "    print(cfd[cfd.conditions()[i]].most_common())\n",
        "    print('--------------')\n",
        "\n",
        "if name_corpus == 'cess_cat':\n",
        "    freq_dist =cfd['Una']\n",
        "else:\n",
        "    freq_dist = cfd['The']\n",
        "\n",
        "print(freq_dist.items())\n",
        "print(freq_dist.max())\n",
        "print(list(freq_dist.elements()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f271edc2",
      "metadata": {
        "id": "f271edc2"
      },
      "source": [
        "Sample text from the language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "0b536851",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b536851",
        "outputId": "ebecddb4-a1de-4fd3-ec4d-5007ce2e7390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'righteousness', 'weather', 'LORD', 'LORD', 'word', 'genius', 'burden', 'righteousness', 'strangers', 'woodman', 'little', 'troubadours', 'LORD', 'mere', 'count', 'WHITE', 'lambs', 'insolence', 'LORD', 'life', 'Emperor', 'landlord', 'king', 'room', 'sons', 'Paradise', 'preparing', 'great', 'two', 'felon', 'passage', 'undiminish', 'summer', 'inhabitants', 'woman', 'Master', 'true', 'word', 'Holy', 'car', 'likeness', 'convict', 'profit', 'cook', 'answer', 'first', 'woman', 'farther', 'sun', 'beans', 'Lord', 'Cat', 'morning', 'Master', 'magistrates', 'penalty', 'Pharisee', 'colloquy', 'priest', 'wake', 'grave', 'light', 'continual', 'land', 'whole', 'whole', 'birth', 'waters', 'strength', 'builder', 'little', 'LORD', 'doctor', 'wicked', 'sons', 'difference', 'three', 'effects', 'danger', 'secret', 'happier', 'banded', 'Miss', 'Country', 'Union', 'stranger', 'young', 'person', 'doors', 'first', 'General', 'law', 'nakedness', 'sun', 'same', 'tempting', 'smile', 'Father', 'rest', 'King']\n",
            "['For', 'dancers', 'fields', 'answer', 'pane', 'official', 'day', 'feet', 'son', 'plenteousness', 'word', 'Caterpillar', 'touch', 'long', '\"', 'universe', 'nations', 'third', 'Marquis', 'name', 'learn', 'barrel', 'first', 'unpent', 'idea', 'Whale', 'guilt', 'fault', 'Queen', 'sixteenth', 'professor', 'human', 'universe', 'grapes', 'country', 'housekeeper', 'starry', 'first', 'subterranean', 'attorney', 'portal', 'amazed', 'humble', 'keeper', 'hours', 'Book', 'servant', 'shock', 'woman', 'very', 'bustle', 'agony', 'LORD', 'brightness', 'spring', 'others', 'Colonel', 'rent', 'way', 'law', 'elders', 'like', 'sun', 'Prairie', 'word', 'singer', 'justified', 'people', 'heaven', 'sky', 'box', 'new', 'human', 'Nantucketer', 'poor', 'children', 'proof', 'clothes', 'stranger', 'poor', 'necessity', 'myth', 'third', 'trouble', 'old', 'rest', 'harpers', 'whole', 'other', 'gallant', 'chaplain', 'first', 'earth', 'snag', 'two', 'clear', 'LORD', 'rich', 'sons', 'king', 'careless']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def sample_bigram_model(cfd_bigrams, last_word, num_words=15):\n",
        "\n",
        "    # TODO\n",
        "    result = [last_word]\n",
        "    for i in range(num_words):\n",
        "      if last_word in cfd_bigrams:\n",
        "        words = []\n",
        "        freqs = []\n",
        "\n",
        "        for word,freq in freq_dist.items():\n",
        "          words.append(word)\n",
        "          freqs.append(freq)\n",
        "\n",
        "        selected_element = random.choices(words, weights=freqs, k=1)[0]\n",
        "        result.append(selected_element)\n",
        "        last_word = selected_element\n",
        "\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    return result\n",
        "\n",
        "if name_corpus=='cess_cat':\n",
        "    print(sample_bigram_model(cfd, 'El', 100))\n",
        "    print(sample_bigram_model(cfd, 'La', 100))\n",
        "    print(sample_bigram_model(cfd, 'Per', 100))\n",
        "else:\n",
        "    print(sample_bigram_model(cfd, 'The', 100))\n",
        "    print(sample_bigram_model(cfd, 'For', 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O4xuRzAqtfeZ",
      "metadata": {
        "id": "O4xuRzAqtfeZ"
      },
      "source": [
        "Extension of previous function to tri, 4... n-grams is long and complicated\n",
        "because conditions of cfd are not one word but lists of pairs, triplets, n-1 words. In addition, the probability of not finding the previous 2, 3..n\n",
        "generated words among the conditions (ngrams) is very high. So better rely\n",
        "on the ``lm`` package of nltk. It has also support for adding ``<s>``, ``</s>`` symbols to sentences (padding), different types of smoothing and backoff, and sampling text.\n",
        "\n",
        "Build a proper language model with support for ``<s>``, ``</s>``, smoothing, backoff, sampling and computation of perplexity. See how here\n",
        "https://www.nltk.org/api/nltk.lm.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "3bf4ae6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf4ae6e",
        "outputId": "b8d5c1c1-333d-41ca-8ba5-2fe563f6d2fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 98552/98552 [00:07<00:00, 13778.31it/s]\n"
          ]
        }
      ],
      "source": [
        "if name_corpus=='cess_cat':\n",
        "    text = []\n",
        "    words_to_remove = ['*0*', '-Fpa-', '-Fpt-']\n",
        "    #for s in tqdm(corpus.sents()[:1000]): # debug or quickly train the network\n",
        "    for s in tqdm(corpus.sents()):\n",
        "        new_s = [w for w in s if w not in words_to_remove]\n",
        "        text.append(new_s[:-1]) # except ending point\n",
        "else:\n",
        "    text = []\n",
        "    for s in tqdm(corpus.sents()):\n",
        "        text.append(s[:-1]) # except ending point\n",
        "\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm.models import MLE, Laplace, StupidBackoff\n",
        "\n",
        "n = 3\n",
        "# TODO:\n",
        "# for each of the three types of language model in last import:\n",
        "#     for n=3, 4, 5 (tri-grams, 4-grams, 5-grams)\n",
        "#         create a model instance\n",
        "#         pad sentences in text\n",
        "#         train the model\n",
        "#         sample a text with 100 words\n",
        "# Hint: do like in ' '.join(['These', 'are', 'some', 'words'])\n",
        "#\n",
        "# Compare results, which combination seems more realistic ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "Wi1iHZ2gwCkT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi1iHZ2gwCkT",
        "outputId": "87f493a4-dbf0-49e8-a000-98539c9d7ca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stupidbackoff\n",
            "For n = 3:\n",
            "\" I am God , which thou sawest ; Where he abides , Transfused on thee do some fishing himself. . 17 : 12 All the unaccomplished works of engineers , Our Willes and Fates do so quickly towards the door of the strange tower , perhaps. , a knop and a half was the son of Kareah , and a distant voice was now set , and see the suds he makes ready for rest , as Perry says that colds have been murdered with the look of real good - humoured notice of Cutler was a man indeed. . \n",
            "-------------\n",
            "For n = 4:\n",
            "17 : 12 And he took them the same fiery emotion accumulated within the Leyden jar of his own cottage with resolute steps , however , that his brother should take his wife , and thy redeemer , the Holy One of Israel , and the Inspector into another , while Mrs . Weston , how could you do so. : But I do assure you that you were born and did not I. a Benjamite , a man lefthanded : and by his power , and by her shewn to her mother , and she trembled till she shook the house , and measured each post of the door was opened unto me of the evil diseases of Egypt , and all the glory of the LORD your God ; and the dragon gave him his power , and by him the children of Israel , did eat their portion which Pharaoh gave them : wherefore they called that place Selahammahlekoth. . 37 : 13 And he went towards the black windows of his shuttered and unlighted inn. \n",
            "-------------\n",
            "For n = 5:\n",
            "37 : 13 And he went forth unto the spring of the day , which were continually bursting forth , Captain Wentworth added :. \" He lives a very lonely life ; he has had to do everything for himself. , Neither against the law of the house of God. , and is faithful with the saints. , 1 : 15 Alas for the day. \n",
            "-------------\n",
            "MLE\n",
            "For n = 3:\n",
            "\" I am God , which thou sawest ; Where he abides , Transfused on thee do some fishing himself. . 17 : 12 All the unaccomplished works of engineers , Our Willes and Fates do so quickly towards the door of the strange tower , perhaps. , a knop and a half was the son of Kareah , and a distant voice was now set , and see the suds he makes ready for rest , as Perry says that colds have been murdered with the look of real good - humoured notice of Cutler was a man indeed. . \n",
            "-------------\n",
            "For n = 4:\n",
            "17 : 12 And he took them the same fiery emotion accumulated within the Leyden jar of his own cottage with resolute steps , however , that his brother should take his wife , and thy redeemer , the Holy One of Israel , and the Inspector into another , while Mrs . Weston , how could you do so. : But I do assure you that you were born and did not I. a Benjamite , a man lefthanded : and by his power , and by her shewn to her mother , and she trembled till she shook the house , and measured each post of the door was opened unto me of the evil diseases of Egypt , and all the glory of the LORD your God ; and the dragon gave him his power , and by him the children of Israel , did eat their portion which Pharaoh gave them : wherefore they called that place Selahammahlekoth. . 37 : 13 And he went towards the black windows of his shuttered and unlighted inn. \n",
            "-------------\n",
            "For n = 5:\n",
            "37 : 13 And he went forth unto the spring of the day , which were continually bursting forth , Captain Wentworth added :. \" He lives a very lonely life ; he has had to do everything for himself. , Neither against the law of the house of God. , and is faithful with the saints. , 1 : 15 Alas for the day. \n",
            "-------------\n",
            "Laplace\n",
            "For n = 3:\n",
            "\" I am James Turnbull the latter plainly saw that great Vow Which did incorporate and make them an everlasting possession. ; 14 : 14 Again , when they see all the embellishments which were coming up to the service in the night here somewhere ,) O soul. , For it hath been in town she would engage to copy , I care not who refused him , Winter - grain sprouts and those that sold doves , Take a tonic , follow close three hundred thousand rams , and ran greedily after the severest exposure , part curb the foaming distance , The furnace , saying , Crucify him , and turn again , and the multiplicity of business , for His sake. . 18 : 13 And he turned that wonderful corner of his coming ; and when they spake unto Moses , saying , What thinkest thou of the hills , by a well of his father that thou surely wakedst weeping from thy judgments , and the Inspector into another country , dwelling in unspeakable bliss ; Made one with her sisters had lately sought each other , staring at earth and green and blue and the wealth or grandeur to do with them. \n",
            "-------------\n",
            "For n = 4:\n",
            "18 : 13 And he was there when Jerusalem was inhabited and in prosperity , and their sockets four. . 39 : 12 And he took them the same fiery emotion accumulated within the Leyden jar of his own creed. . 39 : 12 And he took them the same fiery emotion accumulated within the Leyden jar of his own creed. \n",
            "-------------\n",
            "For n = 5:\n",
            "39 : 12 And she said , Truth , Lord : yet the dogs under the table eat of the children ' s teeth are set on edge. , for a pursuit so full of rage and wildness as the bloody hunt of whales. ; he followed these fish for the fun of it ; and a flattering mouth worketh ruin. . 4 : 2 Wherefore I praised the dead which are already dead more than the living which are yet alive. \n",
            "-------------\n"
          ]
        }
      ],
      "source": [
        "num_sent = 5\n",
        "for model_type in [ StupidBackoff,MLE, Laplace]:\n",
        "  if model_type == MLE:\n",
        "      print(\"MLE\")\n",
        "  elif model_type == Laplace:\n",
        "      print(\"Laplace\")\n",
        "  else:\n",
        "      print(\"Stupidbackoff\")\n",
        "  for n in [3, 4, 5]:\n",
        "    sentences = []\n",
        "    if model_type == StupidBackoff:\n",
        "      lm = model_type(order = n)\n",
        "    else:\n",
        "      lm = model_type(n)\n",
        "    train, vocab = padded_everygram_pipeline(n,text)\n",
        "    lm.fit(train, vocab)\n",
        "\n",
        "    for i in range(num_sent):\n",
        "      content = []\n",
        "      if i == 0:\n",
        "        text_seed = ['<s>']\n",
        "        generated_words = lm.generate(100,text_seed = text_seed,random_seed = 4)\n",
        "        for word in generated_words:\n",
        "          if word == '<s>':\n",
        "            continue\n",
        "          if word == '</s>':\n",
        "            break\n",
        "          content.append(word)\n",
        "      else:\n",
        "        text_seed = sentences[-1][-2:]\n",
        "        generated_words = lm.generate(100,text_seed = text_seed,random_seed = 4)\n",
        "        for word in generated_words:\n",
        "          if word == '<s>':\n",
        "            continue\n",
        "          if word == '</s>':\n",
        "            break\n",
        "          content.append(word)\n",
        "\n",
        "      sentences.append(content)\n",
        "\n",
        "    print(f\"For n = {n}:\")\n",
        "    result = ''\n",
        "    for sentence in sentences:\n",
        "      result +=' '.join(sentence)\n",
        "      result +='. '\n",
        "    print(result)\n",
        "    print('-------------')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
