{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXYMGLM2UTG1"
      },
      "source": [
        "\n",
        "\n",
        "# Sequence Labeling With CRF and HMM - NER\n",
        "\n",
        "The extraction of relevant information from historical handwritten document collections is one of the key steps in order to make these manuscripts available for access and searches. In this context, instead of a pure transcription, the objective is to move towards document understanding. Concretely, the aim is to detect the named entities and assign each of them a semantic category, such as family names, places, occupations, etc.\n",
        "\n",
        "\n",
        "A typical application scenario of named entity recognition is demographic documents, since they contain people's names, birthplaces, occupations, etc. In this scenario, the extraction of the key contents and its storage in databases allows the access to their contents and envision innovative services based in genealogical, social or demographic searches.\n",
        "\n",
        "<p style = 'text-align: center'>\n",
        "<img src = \"http://dag.cvc.uab.es/wp-content/uploads/2016/07/esposalla_detall.jpg\">\n",
        "</p>\n",
        "\n",
        "For further doubts and questions, refer to oriol.ramos@uab.cat and alicia.fornes@uab.cat.\n",
        "\n",
        "Usage of Google Colab is not mandatory, but highly recommended as most of the behaviors are expected for a Linux VM with IPython bindings.\n",
        "\n",
        "## First, we will install the unmet dependencies.\n",
        "\n",
        "This will download some packages and the required data, it may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R8Rcfr3oUAms"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/EauDeData/nlp-resources\n",
        "!cp -r nlp-resources/ resources/\n",
        "!rm -rf nlp-resources/\n",
        "\n",
        "\n",
        "!pip install nltk\n",
        "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite\n",
        "clear_output()\n",
        "\n",
        "from typing import *\n",
        "\n",
        "from itertools import chain\n",
        "import nltk\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import pycrfsuite as crfs\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from resources.data.dataloaders import EsposallesTextDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LbPYoxkYGUa"
      },
      "source": [
        "## Data Curation\n",
        "Loading the dataset - From here you could re-use your previous work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NRLKbU-4UQ8O"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "train_loader = EsposallesTextDataset('resources/data/esposalles/')\n",
        "test_loader = copy.deepcopy(train_loader)\n",
        "test_loader.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzOLIKMGUGAD"
      },
      "source": [
        "Example of data from each loader:\n",
        "> Format string: ```word```:```label```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6nElJ2-ZCJe",
        "outputId": "e3712955-48c2-41a9-a3ec-059501720ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Dilluns:other', 'a:other', '5:other', 'rebere:other', 'de:other', 'Hyacinto:name', 'Boneu:surname', 'hortola:occupation', 'de:other', 'Bara:location', 'fill:other', 'de:other', 'Juan:name', 'Boneu:surname', 'parayre:occupation', 'defunct:other', 'y:other', 'de:other', 'Maria:name', 'ab:other', 'Anna:name', 'donsella:state', 'filla:other', 'de:other', 't:name', 'Cases:surname', 'pages:occupation', 'de:other', 'Bara:location', 'defunct:other', 'y:other', 'de:other', 'Peyrona:name']\n",
            "['Divendres:other', 'a:other', '18:other', 'rebere:other', 'de:other', 'Juan:name', 'Torres:surname', 'pages:occupation', 'habitant:other', 'en:other', 'Sabadell:location', 'fill:other', 'de:other', 'Bernat:name', 'Torres:surname', 'pages:occupation', 'de:other', 'Moya:location', 'bisbat:location', 'de:location', 'Vich:location', 'y:other', 'de:other', 'Antiga:name', 'defucts:other', 'ab:other', 'Margarida:name', 'donsella:state', 'filla:other', 'de:other', 'Juan:name', 'Argemir:surname', 'pages:occupation', 'de:other', 'Sabadell:location', 'y:other', 'de:other', 'Aldonsa:name', 'defuncts:other']\n"
          ]
        }
      ],
      "source": [
        "print([f\"{x}:{y}\" for x,y in zip(*train_loader[0])])\n",
        "print([f\"{x}:{y}\" for x,y in zip(*test_loader[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXOg5M3-lg5J"
      },
      "source": [
        "If the dataset is correctly downloaded you will see two different samples above, and both tests passed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7_mFDqOkcnW",
        "outputId": "9e8119f6-a6e6-48af-e086-61da61928f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set test passed\n",
            "test_set test passed\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "\n",
        "# Dataset ckeck\n",
        "\n",
        "for idx in range(len(train_loader)):\n",
        "\n",
        "  x, y = train_loader[idx]\n",
        "  if len(x) != len(y):\n",
        "    print('train_set test not passed')\n",
        "    break\n",
        "\n",
        "else: print('train_set test passed')\n",
        "\n",
        "for idx in range(len(test_loader)):\n",
        "\n",
        "  x, y = test_loader[idx]\n",
        "  if len(x) != len(y):\n",
        "    print('test_set test not passed')\n",
        "    break\n",
        "\n",
        "else: print('test_set test passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqp5OuN8YTwj"
      },
      "source": [
        "Since most of the computation won't be done with strings, the following function will create a Look Up Table (LUT) that transforms string tokens into ```int``` tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rt-8QpTzYx2e"
      },
      "outputs": [],
      "source": [
        "def create_tokens_lut(train_dataset) -> Dict:\n",
        "  '''\n",
        "  Input:\n",
        "    train_dataset: Training dataset.\n",
        "\n",
        "    Don't tokenize test_set as later on,\n",
        "       we will be considering out-of-vocabulary words as <unk> tokens.\n",
        "\n",
        "    NOTE: Tokens MUST be lowered (.lower()) before considering them.\n",
        "\n",
        "  Ouput:\n",
        "    LUT[Dict]: {\n",
        "      word1: 0,\n",
        "      word2: 1,\n",
        "        ...\n",
        "      wordn: n - 1\n",
        "    }\n",
        "\n",
        "  '''\n",
        "  ct = 0\n",
        "  dict = {}\n",
        "  for i in range(len(train_dataset)):\n",
        "    sentence,_ = train_dataset[i]\n",
        "    for word in sentence:\n",
        "      word = word.lower()\n",
        "      if word not in dict:\n",
        "        dict[word] = ct\n",
        "        ct +=1\n",
        "\n",
        "  return dict\n",
        "\n",
        "\n",
        "LUT = create_tokens_lut(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxkJj8tDe5WA",
        "outputId": "d7bd675f-185d-410a-9656-6fa71367df69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sto', 'arisart', 'buyra', 'conflent', 'llobre', 'darder', 'fabres', 'gatuellas', 'assensio', 'caxaler', 'begas', 'vivints', 'hor', 'gat', 'faneca', 'guardi#', 'villaro', 'tola', 'corties', 'felis', 'busquet', 'muntells', 'auger', 'dimas', 'ge', 'broquets', 'mso', 'nyella', 'rius', 'perris', 'spa', 'sengermes', 'morros', 'valta', 'comptat', 'clavetayre', 'melcior', 'rotxe', 'gusman', 'brasil', 'thome', 'cebriana', 'monblanch', 'payas', 'blanquart', 'theodora', 'plans', 'pallissa', 'poses', 'faliu', 'llorenci', 'moreno', 'ritoreta', 'novell', 'francesa', 'rianna', 'scrivent', 'bonastra', 'honorat', 'bachs', 'castigaleu', 'sitjar', 'arevig', 'campprecios', 'galeras', 'quart', 'victo', 'peramon', 'box', 'campderos', 'gassull', 'dimarts', 'majol', 'ortiz', 'raguera', 'miro', 'tamuyell', 'pachs', 'cabrer', 'monllor', 'macip', 'munmany', 'tibau', 'more', 'angli', 'terre', 'testa', 'ribagossa', 'crich', 'llondra', 'alaverni', 'juan#', 'conteso', 'islla', 'habitants', 'rosa', 'constansa', 'carantela', 'ayguardenter', 'tarafa', 'fabrega', 'jonqueres', 'masseres', 'tisser', 'mandri', 'fargayre', 'comi', 'febres', 'cabus', 'planta', 'deseny', 'idrach', 'sobrevila', 'tatare', 'noguera', 'faja', 'imaginayre', 'cani', 'argemir', 'cabaner', 'debarca', 'fontanilles', 'glandina', 'luciana', 'ratx', 'pinya', 'berenguer', 'garces', 'manader', 'celles', 'aguller', 'vilademaser', 'campanya', 'castellterçol']\n"
          ]
        }
      ],
      "source": [
        "def check_oov_words(LUT = LUT, test_set = test_loader):\n",
        "  oov = set()\n",
        "  for i in range(len(test_set)):\n",
        "    sentence,_ = test_set[i]\n",
        "    for word in sentence:\n",
        "      word = word.lower()\n",
        "      if word not in LUT:\n",
        "        oov.add(word)\n",
        "\n",
        "  return oov\n",
        "\n",
        "print(list(check_oov_words()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zHKqdlAUtly"
      },
      "source": [
        "Due to batch computation of some modules, sequences must have constant length. As a common practice, we will create three new tokens ```<bos>``` and ```<eos>``` for the start and the end of a given sequence and ```<unk>``` for unkown tokens in the application (test) layer or 0 padding during the training. Manually add those tokens to the ```LUT```.\n",
        "\n",
        "\n",
        "Under those constraints, fill the corresponding functions that will post-process each batch. Feel free to code more post-processing functions if you need it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tnpVY5K7iJ9d"
      },
      "outputs": [],
      "source": [
        "LUT['<unk>'] = len(LUT) + 1\n",
        "LUT['<bos>'] = len(LUT) + 1\n",
        "LUT['<eos>'] = len(LUT) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oj0cq0SGUsgF"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 50\n",
        "def complete_seq(X) -> List[List]:\n",
        "\n",
        "  '''\n",
        "\n",
        "    Input:\n",
        "      X: A batch of N sequences [\n",
        "        [word1, ..., wordn],\n",
        "        [word1, ..., wordm]\n",
        "      ]\n",
        "\n",
        "    Output:\n",
        "      A batch of N sequences with MAX_SEQUENCE_LENGTH tokens.\n",
        "        - The starting token will always be <sos>\n",
        "        - The last 'real' token <eos>\n",
        "        - Tokens from <eos> until MAX_SEQUENCE_LENGTH will be <unk> as 0 padding.\n",
        "\n",
        "  '''\n",
        "  for seq in X:\n",
        "    seq = ['<bos>'] + seq + ['<eos>']\n",
        "    diff = MAX_SEQUENCE_LENGTH - len(seq)\n",
        "    for i in range(diff):\n",
        "      seq = seq + ['<unk>']\n",
        "\n",
        "  return X\n",
        "\n",
        "def post_process(X, functions = [complete_seq,]):\n",
        "  for f in functions: X = f(X)\n",
        "  return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKuJPkJOanmB"
      },
      "source": [
        "## NER - Baseline Approach\n",
        "\n",
        "The first approach we will try is based on computing the probabilities for each word in our training corpus. This means computing the most likely category for each word in the dictionary.\n",
        "\n",
        "Compute the test categories predictions and measure the performance for this simple model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rYA9D-twbego"
      },
      "outputs": [],
      "source": [
        "def compute_emissions_dict(dataloader) -> Dict:\n",
        "  '''\n",
        "\n",
        "    Given the train loader ```dataloader```\n",
        "     this function will compute the max likelihood dictionary for each word.\n",
        "\n",
        "  Input:\n",
        "    dataloader: train loader with EsposallesTextDataset\n",
        "\n",
        "  Outputs:\n",
        "    Dict: {\n",
        "      pagès: {name: X occupation: X}, # REMEMBER TO LOWER YOUR TOKENS!\n",
        "            ...\n",
        "      LUT - wordn: {category: x%, ...}\n",
        "    }\n",
        "\n",
        "  '''\n",
        "  counts = {}\n",
        "  dict = {}\n",
        "  for i in range(len(dataloader)):\n",
        "    sentence, tag = dataloader[i]\n",
        "    for word,y in zip(sentence,tag):\n",
        "      word = word.lower()\n",
        "      if word not in counts:\n",
        "        counts[word] = 1\n",
        "      else:\n",
        "        counts[word] +=1\n",
        "\n",
        "      if word not in dict:\n",
        "        dict[word] = {}\n",
        "        dict[word][y] = 1\n",
        "      else:\n",
        "        if y not in dict[word]:\n",
        "          dict[word][y] = 1\n",
        "        else:\n",
        "          dict[word][y] +=1\n",
        "\n",
        "  for word in dict:\n",
        "    for y in dict[word]:\n",
        "      dict[word][y] /= counts[word]\n",
        "\n",
        "  return dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uFQe-5VykF9Q"
      },
      "outputs": [],
      "source": [
        "priors = compute_emissions_dict(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OozkEhtlQow-"
      },
      "source": [
        "At this point, as an example, your emissions dictionary should yield the following emission:\n",
        "\n",
        "$P(location |$ ```Prats``` $) = 18\\%$\n",
        "\n",
        "$P(surname |$ ```Prats``` $) = 72\\%$\n",
        "\n",
        "$P(other |$ ```Prats``` $) = 9\\%$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEFUzlRpQmTa",
        "outputId": "637fe2f6-3487-416e-cadb-8828857e9137"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'location': 0.18181818181818182,\n",
              " 'surname': 0.7272727272727273,\n",
              " 'other': 0.09090909090909091}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "priors['prats']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1JaHhJvcwK8"
      },
      "source": [
        "This method has its limitations in terms of lack of context and, therefore, low expresivity.\n",
        "\n",
        "The following function will compute the confusion matrix for the predictions in the ```test_set``` in order to find the most problematic words.\n",
        "\n",
        "* What do they all have in common?\n",
        "* What kind of words are the least performers?\n",
        "* What's your solution for out-of-vocabulary words? Can you provide a prediction for those?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lDQeZ1_Zcbqx"
      },
      "outputs": [],
      "source": [
        "def predict_test_set(emissions, test_set):\n",
        "\n",
        "  '''\n",
        "\n",
        "  input string: casament eduard pages\n",
        "\n",
        "  prediction: [None, name, occupation]\n",
        "\n",
        "  Important:\n",
        "    Remember to check if you can provide a label for each word (OOVs?).\n",
        "  \n",
        "  '''\n",
        "  predictions = []\n",
        "  for i in range(len(test_set)):\n",
        "    sequence_pred = []\n",
        "    seq, _ = test_set[i]\n",
        "    for word in seq:\n",
        "      word = word.lower()\n",
        "      if word in emissions:\n",
        "        max = 0\n",
        "        t = 'other'\n",
        "        for tag in emissions[word]:\n",
        "          if emissions[word][tag] > max:\n",
        "            max = emissions[word][tag]\n",
        "            t = tag\n",
        "\n",
        "        sequence_pred.append(t)\n",
        "\n",
        "      else:\n",
        "        # We use the tag 'other' for the elements that apper for the first time in the test_set\n",
        "        sequence_pred.append('other')\n",
        "\n",
        "    predictions.append(sequence_pred)\n",
        "\n",
        "  return predictions\n",
        "\n",
        "\n",
        "predictions = predict_test_set(priors, test_loader)\n",
        "\n",
        "def find_common_errors(x_test: List[List], y_pred: List[List], y_true: List[List]) -> Dict:\n",
        "\n",
        "  '''\n",
        "    Input:\n",
        "      x_test: A list with each sample in the corpus with the words for which we\n",
        "ran each prediction\n",
        "          [\n",
        "           ['lorem', 'ipsum', 'dolor', 'sit', 'amet'],\n",
        "           ['Hello', 'world', '!!!'],\n",
        "          ]\n",
        "\n",
        "      y_pred: A list with the predicted labels for each word in x_test corpus.\n",
        "          [\n",
        "           ['1', '0', '0', '1', '2'],\n",
        "           ['2', '1', '0'],\n",
        "          ]\n",
        "\n",
        "      y_true: GT for the x_test sample\n",
        "          [\n",
        "           ['0', '0', '0', '1', '2'],\n",
        "           ['0', '1', '0'],\n",
        "          ]\n",
        "    {\n",
        "      pages: [{'pred': prediction, gt: label}, {'pred': prediction, 'gt': label}, ...]\n",
        "    }\n",
        "  '''\n",
        "  errors = {}\n",
        "  for i in range(len(x_test)):\n",
        "    for word, pred, true in zip(x_test[i], y_pred[i], y_true[i]):\n",
        "      if word not in errors:\n",
        "        errors[word] = []\n",
        "        errors[word].append({'pred':pred, 'gt':true})\n",
        "      else:\n",
        "        errors[word].append({'pred':pred, 'gt':true})\n",
        "\n",
        "  return errors\n",
        "\n",
        "\n",
        "\n",
        "def compute_token_precision(x_test: List[List], y_pred: List[List], y_true: List[List]):\n",
        "  errors = find_common_errors(x_test, y_pred, y_true)\n",
        "  #compute the confusion matrix\n",
        "  #c_matrix[pred][gt] = 30 <=> gt was predicted as pred 30 times\n",
        "  c_matrix = {}\n",
        "  for word in errors:\n",
        "    for pair in errors[word]:\n",
        "      pred, gt = pair['pred'], pair['gt']\n",
        "      if pred not in c_matrix:\n",
        "        c_matrix[pred] = {}\n",
        "        c_matrix[pred][gt] = 1\n",
        "      else:\n",
        "        if gt not in c_matrix[pred]:\n",
        "          c_matrix[pred][gt] = 1\n",
        "        else:\n",
        "          c_matrix[pred][gt]+=1\n",
        "\n",
        "  precision = 0\n",
        "  sum1 = 0\n",
        "  sum2 = 0\n",
        "  for pred in c_matrix:\n",
        "    sum1 += c_matrix[pred][pred]\n",
        "    for gt in c_matrix[pred]:\n",
        "      sum2 += c_matrix[pred][gt]\n",
        "\n",
        "  precision = sum1 / sum2\n",
        "  return precision\n",
        "\n",
        "  #{'location':{'location':49, 'surname':23},'surname':{}}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-bjHuqWLH_w",
        "outputId": "91049d2d-b8c2-4283-b675-177c5ed3efc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'pred': 'name', 'gt': 'location'},\n",
              " {'pred': 'name', 'gt': 'surname'},\n",
              " {'pred': 'name', 'gt': 'location'}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_common_errors([test_loader[idx][0] for idx in range(len(test_loader))], predictions, [test_loader[idx][1] for idx in range(len(test_loader))])['Esteva']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0x26Dug_nD1",
        "outputId": "9179948d-1375-4704-8554-8e6aa87758a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.885741873189572"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_token_precision([test_loader[idx][0] for idx in range(len(test_loader))], predictions, [test_loader[idx][1] for idx in range(len(test_loader))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcbFfmVA-c3P",
        "outputId": "199f780c-63e8-4d2e-c262-c357049e5dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['other', 'other', 'other', 'other', 'other', 'name', 'name', 'occupation', 'other', 'location', 'other', 'other', 'name', 'name', 'occupation', 'other', 'location', 'other', 'other', 'other', 'other', 'other', 'other', 'name', 'other', 'name', 'other', 'state', 'other', 'other', 'name', 'other', 'occupation', 'other', 'location', 'other', 'other', 'name', 'other']\n",
            "['other', 'other', 'other', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'other', 'other', 'other', 'other', 'name', 'other', 'name', 'name', 'state', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'name', 'other']\n"
          ]
        }
      ],
      "source": [
        "print(predictions[2])\n",
        "print(test_loader[2][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pv08c-3_wTV"
      },
      "source": [
        "The task involved Named Entity Recognition (NER) in historical handwritten documents, aiming to categorize entities like family names, places, and occupations. The current method employs a basic approach, assigning the most likely category to each word based on training data, but it lacks context and struggles with out-of-vocabulary (OOV) words. OOV words are currently labeled with the most frequent category, which may not be ideal. Analysis of the confusion matrix and common errors highlights areas for improvement, suggesting the incorporation of context-aware methods and better OOV handling techniques. These enhancements could enhance performance and accuracy in NER for historical handwritten documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGLLJH44fUce"
      },
      "source": [
        "## HMM Approach\n",
        "\n",
        "As demonstrated in the previous experiment, using just the priors have not enough expresivity for managing both out of vocabulary words and polysemic words. Here we will use the ```python-crfsuite``` module to build a Hidden Markov Model and improve the predictions on ```test_set```.\n",
        "\n",
        "Check <a href = 'https://python-crfsuite.readthedocs.io/en/latest/'>here</a> the  ```python-crfsuite``` documentation.\n",
        "\n",
        "First, we will set up the parameters for our CRF model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lnnMYLlp94mz"
      },
      "outputs": [],
      "source": [
        "def get_word_to_hmm_features(sent, i):\n",
        "\n",
        "\n",
        "    '''\n",
        "     Reminder:\n",
        "        The Markov assumption states that the transition for the i-th token\n",
        "          depends on the (i-1)-th token.\n",
        "\n",
        "\n",
        "    '''\n",
        "    word, _ = sent[i]\n",
        "    #emission probilities\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "    ]\n",
        "    if i == 0:\n",
        "        features.append('bos')\n",
        "\n",
        "    if (i == len(sent) - 1):\n",
        "        features.append('eos')\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2HMMfeatures(sent):\n",
        "    return [get_word_to_hmm_features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jz5HDNLApC5U"
      },
      "outputs": [],
      "source": [
        "# transform the dataset\n",
        "# to the (token, gt) tuple format\n",
        "train_sents = [  [(x,y) for x,y in zip(*train_loader[idx])] for idx in range(len(train_loader))]\n",
        "test_sents =  [  [(x,y) for x,y in zip(*test_loader[idx])] for idx in range(len(test_loader))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wLh9W9_SWWP",
        "outputId": "df1c4b2f-ec61-41b8-df19-847bafaa18c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Dilluns', 'other'), ('a', 'other'), ('5', 'other'), ('rebere', 'other'), ('de', 'other'), ('Hyacinto', 'name'), ('Boneu', 'surname'), ('hortola', 'occupation'), ('de', 'other'), ('Bara', 'location'), ('fill', 'other'), ('de', 'other'), ('Juan', 'name'), ('Boneu', 'surname'), ('parayre', 'occupation'), ('defunct', 'other'), ('y', 'other'), ('de', 'other'), ('Maria', 'name'), ('ab', 'other'), ('Anna', 'name'), ('donsella', 'state'), ('filla', 'other'), ('de', 'other'), ('t', 'name'), ('Cases', 'surname'), ('pages', 'occupation'), ('de', 'other'), ('Bara', 'location'), ('defunct', 'other'), ('y', 'other'), ('de', 'other'), ('Peyrona', 'name')]\n"
          ]
        }
      ],
      "source": [
        "print(train_sents[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nlPACtd-kFlv"
      },
      "outputs": [],
      "source": [
        "X_train = [sent2HMMfeatures(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2HMMfeatures(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jIOvOkloh8lr"
      },
      "outputs": [],
      "source": [
        "trainer = crfs.Trainer(verbose=False) # Instance a CRF trainer\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq) # Stack the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SGN9gHxQsiX3"
      },
      "outputs": [],
      "source": [
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # Max Number of iterations for the iterative algorithm\n",
        "\n",
        "    # include transitions that are possible, but not observed (smoothing)\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nSheENbslnu",
        "outputId": "516823e7-d7b3-49e3-ffd5-62c7d14497f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 490 ms, sys: 2.03 ms, total: 492 ms\n",
            "Wall time: 494 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "trainer.train('npl_ner_crf.crfsuite') # Train the model and save it locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqj33gJNswgI",
        "outputId": "1f1f152b-aaf9-4dbc-8ae3-aa70caf958f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7bd2fd8fdf90>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tagger = crfs.Tagger()\n",
        "tagger.open('npl_ner_crf.crfsuite') # Load the inference API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEkGkeIA0THW",
        "outputId": "5e1367e6-7a40-4e46-d41b-74c1247588fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Divendres', 'other'), ('a', 'other'), ('18', 'other'), ('rebere', 'other'), ('de', 'other'), ('Juan', 'name'), ('Torres', 'surname'), ('pages', 'occupation'), ('habitant', 'other'), ('en', 'other'), ('Sabadell', 'location'), ('fill', 'other'), ('de', 'other'), ('Bernat', 'name'), ('Torres', 'surname'), ('pages', 'occupation'), ('de', 'other'), ('Moya', 'location'), ('bisbat', 'location'), ('de', 'location'), ('Vich', 'location'), ('y', 'other'), ('de', 'other'), ('Antiga', 'name'), ('defucts', 'other'), ('ab', 'other'), ('Margarida', 'name'), ('donsella', 'state'), ('filla', 'other'), ('de', 'other'), ('Juan', 'name'), ('Argemir', 'surname'), ('pages', 'occupation'), ('de', 'other'), ('Sabadell', 'location'), ('y', 'other'), ('de', 'other'), ('Aldonsa', 'name'), ('defuncts', 'other')]\n"
          ]
        }
      ],
      "source": [
        "print(test_sents[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7x8egb-s576",
        "outputId": "588d0ee1-ad6f-4d17-d6d7-1a9c67c86517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Divendres a 18 rebere de Juan Torres pages habitant en Sabadell fill de Bernat Torres pages de Moya bisbat de Vich y de Antiga defucts ab Margarida donsella filla de Juan Argemir pages de Sabadell y de Aldonsa defuncts\n",
            "\n",
            "Predicted: other other other other other name surname occupation other other location other other name surname occupation other location location location location other other name other other name state other other name surname occupation other location other other name other\n",
            "Correct:   other other other other other name surname occupation other other location other other name surname occupation other location location location location other other name other other name state other other name surname occupation other location other other name other\n"
          ]
        }
      ],
      "source": [
        "example_sent = test_sents[0]\n",
        "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
        "\n",
        "print(\"Predicted:\", ' '.join(tagger.tag(sent2HMMfeatures(example_sent))))\n",
        "print(\"Correct:  \", ' '.join(sent2labels(example_sent))) # Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TEJ7BVnQtGYr"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "\n",
        "    Classification report.\n",
        "    You can use this as evaluation for both in the baseline model and new model.\n",
        "\n",
        "    \"\"\"\n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "\n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "\n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eS74uUQ-tNae"
      },
      "outputs": [],
      "source": [
        "# Compute the predictions\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chj7a8cK9s5L",
        "outputId": "4734ded7-c55e-4f6b-b42e-8a80019165ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['other', 'other', 'other', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'name', 'surname', 'occupation', 'occupation', 'other', 'other', 'name', 'other', 'name', 'state', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'name']\n",
            "['other', 'other', 'other', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'name', 'surname', 'surname', 'occupation', 'other', 'other', 'name', 'other', 'name', 'state', 'other', 'other', 'name', 'surname', 'occupation', 'other', 'location', 'other', 'other', 'name']\n"
          ]
        }
      ],
      "source": [
        "print(y_pred[1])\n",
        "print(y_test[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pernKQrdd0uF"
      },
      "source": [
        "* Use the  ```bio_classification_report``` function in both the Baseline model and the HMM model. Do you observe any improvement? In which cases does it still fail?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC90MFOTeTsW",
        "outputId": "2a5a513c-fffe-4dd7-d987-cbb33bd65497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    location       0.94      0.71      0.81       462\n",
            "        name       0.94      0.95      0.94       494\n",
            "  occupation       0.94      0.85      0.90       294\n",
            "       other       0.85      0.99      0.91      1493\n",
            "       state       0.98      0.95      0.96       113\n",
            "     surname       0.84      0.47      0.60       251\n",
            "\n",
            "   micro avg       0.89      0.89      0.89      3107\n",
            "   macro avg       0.91      0.82      0.85      3107\n",
            "weighted avg       0.89      0.89      0.88      3107\n",
            " samples avg       0.89      0.89      0.89      3107\n",
            "\n",
            "HMM classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    location       0.89      0.92      0.91       462\n",
            "        name       0.98      0.96      0.97       494\n",
            "  occupation       0.94      0.92      0.93       294\n",
            "       other       0.97      0.98      0.97      1493\n",
            "       state       0.98      0.95      0.96       113\n",
            "     surname       0.94      0.93      0.93       251\n",
            "\n",
            "   micro avg       0.96      0.96      0.96      3107\n",
            "   macro avg       0.95      0.94      0.95      3107\n",
            "weighted avg       0.96      0.96      0.96      3107\n",
            " samples avg       0.96      0.96      0.96      3107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Comparison of the baseline\n",
        "### Perform both quantitative and qualitative analysis\n",
        "baseline_pred = predict_test_set(priors, test_loader)\n",
        "baseline_true = [test_loader[i][1] for i in range(len(test_loader))]\n",
        "\n",
        "hmm_pred = y_pred\n",
        "\n",
        "print(\"Baseline classification report:\")\n",
        "print(bio_classification_report(baseline_true, baseline_pred))\n",
        "\n",
        "print(\"HMM classification report:\")\n",
        "print(bio_classification_report(y_test, hmm_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2vyruN3D9bK"
      },
      "source": [
        "The HMM model shows significant improvements over the baseline, which relies heavily on emission probabilities. However, the baseline has limitations:\n",
        "\n",
        "Contextual Understanding: It overlooks context, leading to errors when a word's meaning depends on neighboring words.\n",
        "\n",
        "Out-of-Vocabulary Words: Performance suffers with out-of-vocabulary words, often resorting to assigning the most frequent label.\n",
        "\n",
        "Neglects Label Transitions: It doesn't consider transitions between labels, missing valuable information.\n",
        "\n",
        "Ignores Higher-Order Dependencies: Lacks consideration for relationships between non-adjacent words, essential for accurate labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJzlgKUEWdS"
      },
      "source": [
        "Quantitative and Qualitative Analysis of HMM and Baseline Models\n",
        "\n",
        "The HMM model is generally expected to outperform the Baseline model due to its consideration of tag dependencies. However, there are instances where the HMM model may falter, such as:\n",
        "\n",
        "Data Ambiguity: Both models may struggle if the data contains ambiguity or inconsistencies in annotation.\n",
        "\n",
        "Rare or Unseen Words/Entities: The HMM model may fail when encountering rare or unseen words/entities during testing, lacking information for accurate predictions.\n",
        "\n",
        "Complex Tag Dependencies: In cases of intricate tag dependencies, the HMM model may still struggle to make accurate predictions.\n",
        "\n",
        "To pinpoint the HMM model's failures, analyzing the confusion matrix can identify common misclassifications, offering insights for model improvement or the need for additional training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYr3LJuueuIV"
      },
      "source": [
        "* Can this model provide a solution for out-of-vocabulary words?\n",
        "* Can you provide examples of words which changed its category compared to the max-likelihood prior when introducing context? See the following example.\n",
        "\n",
        "$P($ ```Noun |people``` $) = 80\\%$\n",
        "\n",
        "$P($ ``` people, Noun | \"a  planet\" ``` $) = 5\\%$\n",
        "\n",
        "$P($ ``` people, Verb | \"a  planet\" ``` $) = 90\\%$\n",
        "\n",
        "* How does it perform with respect to the out-of-vocabulary words? e.g. what's the precision for those?\n",
        "\n",
        "*  The following function shows the less likely and most likely transitions. Comment them and perform a deep analysis on each transition, do they have something in common with the errors you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbuAZMRHEFF9"
      },
      "source": [
        "Handling Out-of-Vocabulary Words:\n",
        "The HMM model struggles with out-of-vocabulary (OOV) words as it lacks specific emission probabilities for unseen words. It may resort to assigning the most frequent label or making arbitrary predictions based on transition probabilities. Advanced techniques like smoothing can help mitigate this issue.\n",
        "\n",
        "Examples of Contextual Change in Word Category:\n",
        "Consider the word \"run\":\n",
        "\n",
        "P(Verb | run) = 70%\n",
        "P(run, Verb | \"a race\") = 90%\n",
        "P(run, Noun | \"a race\") = 10%\n",
        "\n",
        "In this case, when \"run\" is observed in the context of \"a race,\" it is more likely to be categorized as a verb (90%) rather than a noun (10%), contrary to its standalone probability of being a verb (70%).\n",
        "\n",
        "Performance on Out-of-Vocabulary Words:\n",
        "The model's precision for out-of-vocabulary words depends on its handling of such instances. If it assigns the most frequent label to all OOV words, precision may be higher. However, if the model struggles with OOV words and makes arbitrary predictions, precision may be lower. Separate evaluation of OOV words is crucial to assess model robustness.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SCZTNwetk9e",
        "outputId": "bc3d65e7-976b-4146-c836-7e78fdd67fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "surname -> occupation 5.019786\n",
            "location -> location 4.249178\n",
            "occupation -> occupation 4.194908\n",
            "name   -> surname 3.918272\n",
            "surname -> surname 3.294527\n",
            "other  -> name    2.642988\n",
            "name   -> name    2.280106\n",
            "other  -> location 1.814986\n",
            "occupation -> other   1.799188\n",
            "state  -> state   1.515564\n",
            "name   -> state   1.182575\n",
            "other  -> other   1.181984\n",
            "state  -> other   0.735261\n",
            "occupation -> state   0.467426\n",
            "location -> other   0.403282\n",
            "\n",
            "Top unlikely transitions:\n",
            "state  -> occupation 0.214062\n",
            "surname -> state   0.070542\n",
            "location -> occupation -0.072833\n",
            "name   -> other   -0.506374\n",
            "occupation -> name    -0.617364\n",
            "other  -> surname -0.626089\n",
            "occupation -> location -0.735001\n",
            "surname -> name    -0.998662\n",
            "other  -> occupation -1.030786\n",
            "other  -> state   -1.296538\n",
            "name   -> occupation -1.650451\n",
            "occupation -> surname -2.111763\n",
            "name   -> location -2.166658\n",
            "location -> surname -2.771394\n",
            "location -> name    -3.351583\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "info = tagger.info()\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(info.transitions).most_common(15))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(info.transitions).most_common()[-15:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmxKfyFDtq8k",
        "outputId": "6ce39a62-2474-4c0c-db4d-4a42dda89586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top positive:\n",
            "10.471530 state  word.lower=viudo\n",
            "9.201264 state  word.lower=donsella\n",
            "9.171407 other  word.lower=ab\n",
            "9.073835 other  word.lower=fill\n",
            "9.043569 other  word.lower=defuncts\n",
            "8.975021 other  word.lower=#\n",
            "8.538504 state  word.lower=viuda\n",
            "8.204700 other  word.lower=defunct\n",
            "7.974212 other  word.lower=y\n",
            "7.971931 other  word.lower=defuncta\n",
            "7.816721 location word.lower=frances\n",
            "7.655355 state  word.lower=dosella\n",
            "7.522998 other  word.lower=rebere\n",
            "7.259508 other  word.lower=habitant\n",
            "7.223392 location word.lower=bara\n",
            "7.056602 other  word.lower=a\n",
            "6.963770 other  word.lower=de\n",
            "6.655697 other  word.lower=filla\n",
            "6.586878 other  word.lower=habitat\n",
            "6.535491 occupation word.lower=llana\n",
            "\n",
            "Top negative:\n",
            "0.009387 occupation word.lower=pastisser\n",
            "0.006814 surname word.lower=pere\n",
            "-0.000147 name   word.lower=sr\n",
            "-0.000667 location word.lower=dels\n",
            "-0.015598 location word.lower=menat\n",
            "-0.061897 surname word.lower=vila\n",
            "-0.086558 surname word.lower=del\n",
            "-0.118397 surname word.lower=toni\n",
            "-0.285311 occupation bias\n",
            "-0.398388 location word.lower=habitant\n",
            "-0.422007 surname eos\n",
            "-0.499756 location word.lower=pages\n",
            "-0.504381 surname word.lower=texidor\n",
            "-0.558585 surname word.lower=y\n",
            "-0.694049 surname word.lower=#\n",
            "-0.757626 state  bias\n",
            "-1.027974 occupation word.lower=del\n",
            "-1.104222 location word.lower=en\n",
            "-1.170696 surname word.lower=serrat\n",
            "-1.568957 location word.lower=domiciliat\n"
          ]
        }
      ],
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-6s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(info.state_features).most_common(20))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(info.state_features).most_common()[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbL6j-pnGeAw"
      },
      "source": [
        "\n",
        "In this analysis, the model shows strong associations:\n",
        "\n",
        "Surname -> Occupation, Occupation -> Occupation: Recognizes an occupation often follows a surname, and consecutive words can belong to the occupation category.\n",
        "Location -> Location: Identifies consecutive location-related words.\n",
        "Name -> Surname, Surname -> Surname: Understands the relationship between names and surnames; consecutive surnames may appear.\n",
        "Top unlikely transitions reveal less probable transitions:\n",
        "\n",
        "Location -> Name, Surname, Occupation: Indicates locations rarely transition directly to names, surnames, or occupations.\n",
        "Name -> Occupation, Occupation -> Surname, Name: Shows uncommon transitions, possibly related to errors. For example, if transitioning from a location to a surname is unlikely, the model may struggle to identify correct sequences where this transition occurs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmN-eYcyNP-n"
      },
      "source": [
        "## Hyperparameter Exploration\n",
        "\n",
        "In the definition of the model we used some default hyperparameters related to the training algorithm.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # Max Number of iterations for the iterative algorithm\n",
        "\n",
        "    # include transitions that are possible, but not observed (smoothing)\n",
        "    'feature.possible_transitions': True\n",
        "})\n",
        "```\n",
        "Can you improve the precision by better parametrization? Feel free to explore more parameters through [the documentation](https://sklearn-crfsuite.readthedocs.io/en/latest/api.html#sklearn_crfsuite.CRF).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NIPpnIfJf1w6"
      },
      "outputs": [],
      "source": [
        "# New parameters and results here\n",
        "## Use the functions above, no need to re-work.\n",
        "## There is no need of a deep analysis nor qualitative evaluation\n",
        "param_grid = {\n",
        "    'c1': [0.01, 0.1, 1, 10], # Coefficient for L1 regularization penalty\n",
        "    'c2': [0.01, 0.1, 1, 10], # Coefficient for L2 regularization penalty\n",
        "\n",
        "    # Different algorithms (Gradient descent using the L-BFGS method\n",
        "\n",
        "    'algorithm': ['lbfgs', # 'l2sgd' - Stochastic Gradient Descent with L2 regularization term\n",
        "                  'ap', # 'ap' - Averaged Perceptron\n",
        "                  'pa', # 'pa' - Passive Aggressive (PA)\n",
        "                  'arow'], # 'arow' - Adaptive Regularization Of Weight Vector (AROW) )\n",
        "\n",
        "    'max_iterations': 100, # Maximum number of iterations\n",
        "    'epsilon':00.1         # The epsilon parameter that determines the condition of convergence.\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4lJF5SrkVHQ"
      },
      "source": [
        "## CRF Approach\n",
        "\n",
        "Additionaly, we can address the problem by adding complexity to the transition probabilities. In contrast to HMM, a CRF isn't subject to locality constraints when computing the posterior probabilities.\n",
        "\n",
        "Implement a CRF word featurer that takes into account tokens beyond adjacent ones and your expected needs given the qualitative evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hdB-tM1qNPtP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_word_to_crf_features(sentence, word_idx):\n",
        "    word, _ = sentence[word_idx]\n",
        "\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "    ]\n",
        "\n",
        "    if word_idx > 0:\n",
        "        prev_word, _ = sentence[word_idx - 1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + prev_word.lower(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('bos')\n",
        "\n",
        "    if word_idx < len(sentence) - 1:\n",
        "        next_word, _ = sentence[word_idx + 1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + next_word.lower(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('eos')\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_sent_to_crf_features(sentence):\n",
        "    return [get_word_to_crf_features(sentence, i) for i in range(len(sentence))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oOf5yEumg0uE"
      },
      "outputs": [],
      "source": [
        "X_train = [get_sent_to_crf_features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [get_sent_to_crf_features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]\n",
        "\n",
        "trainer_crf = crfs.Trainer(verbose=False) # Instance a CRF trainer\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer_crf.append(xseq, yseq) # Stack the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mscLAiChg3wa"
      },
      "outputs": [],
      "source": [
        "trainer_crf.set_params({\n",
        "\n",
        "    'c1': 0.01,  # coefficient for L1 penalty\n",
        "    'c2': 0.01,  # coefficient for L2 penalty\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYnITa2ahaug",
        "outputId": "565bfd07-ad2c-4194-f27a-bbf00c137e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7bd32f276b90>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_crf.train('npl_ner_crf-improved.crfsuite') # Train the model and save it locally.\n",
        "tagger_crf = crfs.Tagger()\n",
        "tagger_crf.open('npl_ner_crf.crfsuite') # Load the inference API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhFqQnvOhzA7"
      },
      "source": [
        "* Did the results improve? Comment your decision on the features used in the CRF approach. Is there a difference between using just adjacent tokens or unconstrained optimization?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypNM0UfqhtLT",
        "outputId": "88246087-6cf8-4547-be81-bf3d83bad2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRF Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    location       0.89      0.92      0.91       462\n",
            "        name       0.98      0.96      0.97       494\n",
            "  occupation       0.94      0.92      0.93       294\n",
            "       other       0.97      0.98      0.97      1493\n",
            "       state       0.98      0.95      0.96       113\n",
            "     surname       0.94      0.93      0.93       251\n",
            "\n",
            "   micro avg       0.96      0.96      0.96      3107\n",
            "   macro avg       0.95      0.94      0.95      3107\n",
            "weighted avg       0.96      0.96      0.96      3107\n",
            " samples avg       0.96      0.96      0.96      3107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Quantitative and qualitative evaluation\n",
        "\n",
        "y_pred_crf = [tagger_crf.tag(x) for x in X_test]\n",
        "\n",
        "report_crf = bio_classification_report(y_test, y_pred_crf)\n",
        "print(\"CRF Model:\")\n",
        "print(report_crf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYxSRFdoJYGB"
      },
      "source": [
        "\n",
        "Using only adjacent tokens in the CRF model may restrict its context understanding. Employing unconstrained optimization allows the model to consider a broader token range, enhancing its grasp of word-label relationships and potentially improving results. However, assessing the model's performance on the test set is crucial to confirm whether this approach indeed yields better predictions.\n",
        "The results for both models were the same for all labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa8EqtjvisI7"
      },
      "source": [
        "## Conclusions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak0r9CPEjEb0"
      },
      "source": [
        "This notebook explores three Named Entity Recognition methods: a baseline model, Hidden Markov Model, and Conditional Random Field, all using the BIO tagging scheme. We analyze their performance and discuss strengths and weaknesses.\n",
        "\n",
        "Choosing the NER model depends on task requirements and resource availability. The baseline model suits simple tasks, while HMM and CRF models offer superior performance with increased complexity and computational requirements. CRF is especially effective for complex NER tasks requiring diverse features and non-local context."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
