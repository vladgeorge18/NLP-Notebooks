{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n",
      "PoS: [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'NN'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), ('Arthur', 'NNP'), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n",
      "['Good', 'muffins', 'cost', '$3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = \"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\n",
    "tokens = nltk.word_tokenize(sentence) # Tokenize\n",
    "print(tokens)\n",
    "tagged = nltk.pos_tag(tokens) # PoS tagging\n",
    "print(\"PoS:\",tagged)\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "s = \"Good muffins cost $3.88\\nin New York. Please buy me two of them.\\n\\nThanks.\"\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "output = tokenizer.tokenize(s)\n",
    "print(output)\n",
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "['The', 'Jamaica', 'Observer', 'reported', 'that', 'Usain', 'Bolt', 'broke', 'the', '100m', 'record', '.']\n",
      "PoS: [('The', 'DT'), ('Jamaica', 'NNP'), ('Observer', 'NNP'), ('reported', 'VBD'), ('that', 'DT'), ('Usain', 'NNP'), ('Bolt', 'NNP'), ('broke', 'VBD'), ('the', 'DT'), ('100m', 'CD'), ('record', 'NN'), ('.', '.')]\n",
      " \n",
      "Sentence 2\n",
      "['While', 'hunting', 'in', 'Africa', ',', 'I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas', '.', 'How', 'an', 'elephant', 'got', 'into', 'my', 'pajamas', 'I', \"'ll\", 'never', 'know']\n",
      "PoS: [('While', 'IN'), ('hunting', 'VBG'), ('in', 'IN'), ('Africa', 'NNP'), (',', ','), ('I', 'PRP'), ('shot', 'VBP'), ('an', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NN'), ('.', '.'), ('How', 'WRB'), ('an', 'DT'), ('elephant', 'JJ'), ('got', 'VBD'), ('into', 'IN'), ('my', 'PRP$'), ('pajamas', 'NN'), ('I', 'PRP'), (\"'ll\", 'MD'), ('never', 'RB'), ('know', 'VB')]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "sentences =[\"The Jamaica Observer reported that Usain Bolt broke the 100m record.\", \"While hunting in Africa, I shot an elephant in my pajamas. How an elephant got into my pajamas I'll never know\"]\n",
    "count = 1\n",
    "for sentence in sentences:\n",
    "    print(f\"Sentence {count}\")\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    print(tokens)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    print(\"PoS:\",tagged)\n",
    "    count +=1\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START grammar: S\n",
      "PRODUCTIONS grammar: [S -> NP VP, PP -> P NP, NP -> Det N, NP -> Det N PP, NP -> 'I', NP -> 'You', VP -> V NP, VP -> VP PP, Det -> 'an', Det -> 'my', N -> 'elephant', N -> 'pajamas', V -> 'shot', P -> 'in']\n",
      "|.  I  . shot.  an .eleph.  in .  my .pajam.|\n",
      "Leaf Init Rule:\n",
      "|[-----]     .     .     .     .     .     .| [0:1] 'I'\n",
      "|.     [-----]     .     .     .     .     .| [1:2] 'shot'\n",
      "|.     .     [-----]     .     .     .     .| [2:3] 'an'\n",
      "|.     .     .     [-----]     .     .     .| [3:4] 'elephant'\n",
      "|.     .     .     .     [-----]     .     .| [4:5] 'in'\n",
      "|.     .     .     .     .     [-----]     .| [5:6] 'my'\n",
      "|.     .     .     .     .     .     [-----]| [6:7] 'pajamas'\n",
      "Bottom Up Predict Combine Rule:\n",
      "|[-----]     .     .     .     .     .     .| [0:1] NP -> 'I' *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|[----->     .     .     .     .     .     .| [0:1] S  -> NP * VP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     [-----]     .     .     .     .     .| [1:2] V  -> 'shot' *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     [----->     .     .     .     .     .| [1:2] VP -> V * NP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     [-----]     .     .     .     .| [2:3] Det -> 'an' *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N\n",
      "|.     .     [----->     .     .     .     .| [2:3] NP -> Det * N PP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     [-----]     .     .     .| [3:4] N  -> 'elephant' *\n",
      "Single Edge Fundamental Rule:\n",
      "|.     .     [-----------]     .     .     .| [2:4] NP -> Det N *\n",
      "|.     .     [----------->     .     .     .| [2:4] NP -> Det N * PP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     [----------->     .     .     .| [2:4] S  -> NP * VP\n",
      "Single Edge Fundamental Rule:\n",
      "|.     [-----------------]     .     .     .| [1:4] VP -> V NP *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     [----------------->     .     .     .| [1:4] VP -> VP * PP\n",
      "Single Edge Fundamental Rule:\n",
      "|[-----------------------]     .     .     .| [0:4] S  -> NP VP *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     .     [-----]     .     .| [4:5] P  -> 'in' *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     .     [----->     .     .| [4:5] PP -> P * NP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     .     .     [-----]     .| [5:6] Det -> 'my' *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N\n",
      "|.     .     .     .     .     [----->     .| [5:6] NP -> Det * N PP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     .     .     .     [-----]| [6:7] N  -> 'pajamas' *\n",
      "Single Edge Fundamental Rule:\n",
      "|.     .     .     .     .     [-----------]| [5:7] NP -> Det N *\n",
      "|.     .     .     .     .     [----------->| [5:7] NP -> Det N * PP\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     .     .     .     [----------->| [5:7] S  -> NP * VP\n",
      "Single Edge Fundamental Rule:\n",
      "|.     .     .     .     [-----------------]| [4:7] PP -> P NP *\n",
      "Single Edge Fundamental Rule:\n",
      "|.     .     [-----------------------------]| [2:7] NP -> Det N PP *\n",
      "|.     [-----------------------------------]| [1:7] VP -> VP PP *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     [----------------------------------->| [1:7] VP -> VP * PP\n",
      "Single Edge Fundamental Rule:\n",
      "|[=========================================]| [0:7] S  -> NP VP *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     .     [----------------------------->| [2:7] S  -> NP * VP\n",
      "Single Edge Fundamental Rule:\n",
      "|.     [-----------------------------------]| [1:7] VP -> V NP *\n",
      "Bottom Up Predict Combine Rule:\n",
      "|.     [----------------------------------->| [1:7] VP -> VP * PP\n",
      "Single Edge Fundamental Rule:\n",
      "|[=========================================]| [0:7] S  -> NP VP *\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "from nltk import CFG\n",
    "# Defining a grammar\n",
    "groucho_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I' | 'You'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")\n",
    "# Printing the grammar\n",
    "print(\"START grammar:\",groucho_grammar.start())\n",
    "print(\"PRODUCTIONS grammar:\",groucho_grammar.productions())\n",
    "text = \"I shot an elephant in my pajamas\"\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "# Parsing the text\n",
    "parser = nltk.parse.chart.ChartParser(groucho_grammar,trace=2)\n",
    "trees = parser.parse(text_tokens)\n",
    "for t in trees:\n",
    " print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: John saw a man with my telescope\n",
      "(S\n",
      "  (NP John)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det a) (N man)))\n",
      "    (PP (P with) (NP (Det my) (N telescope)))))\n",
      "(S\n",
      "  (NP John)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P with) (NP (Det my) (N telescope))))))\n",
      "\n",
      "Text: Alex kissed the dog\n",
      "(S (NP Alex) (VP (V kissed) (NP (Det the) (N dog))))\n",
      "\n",
      "Text: the man with the telescope ate a sandwich in the park\n",
      "(S\n",
      "  (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))\n",
      "  (VP\n",
      "    (VP (V ate) (NP (Det a) (N sandwich)))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n",
      "(S\n",
      "  (NP (Det the) (N man) (PP (P with) (NP (Det the) (N telescope))))\n",
      "  (VP\n",
      "    (V ate)\n",
      "    (NP (Det a) (N sandwich) (PP (P in) (NP (Det the) (N park))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mytexts_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP \n",
    "PP -> P NP\n",
    "NP -> N | Det N | Det N PP | 'I' | 'You' | 'John' | 'Alex' \n",
    "VP -> V NP | VP PP\n",
    "Det -> 'a' | 'the' | 'my'\n",
    "N -> 'man' | 'telescope' | 'dog' | 'sandwich' | 'park'\n",
    "V -> 'saw' | 'kissed' | 'ate'\n",
    "P -> 'with' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "# List of texts\n",
    "mytexts = [\n",
    "    \"John saw a man with my telescope\",\n",
    "    \"Alex kissed the dog\",\n",
    "    \"the man with the telescope ate a sandwich in the park\"]\n",
    "\n",
    "for text in mytexts:\n",
    "    print(\"Text:\", text)\n",
    "    text_tokens = nltk.word_tokenize(text)\n",
    "    parser = nltk.parse.chart.ChartParser(mytexts_grammar, trace=0)\n",
    "    trees = parser.parse(text_tokens)\n",
    "    for t in trees:\n",
    "        print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have more than one tree for the same sentence, because the VP can be split in 2 different ways for the first and third sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I saw a dog with a telescope\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det a) (N dog)))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N dog) (PP (P with) (NP (Det a) (N telescope))))))\n"
     ]
    }
   ],
   "source": [
    "text = \"I saw a dog with a telescope\"\n",
    "print(\"Text:\", text)\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "parser = nltk.parse.chart.ChartParser(mytexts_grammar, trace=0)\n",
    "trees = parser.parse(text_tokens)\n",
    "for t in trees:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: with my telescope I saw a dog\n"
     ]
    }
   ],
   "source": [
    "text = \"with my telescope I saw a dog\"\n",
    "print(\"Text:\", text)\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "parser = nltk.parse.chart.ChartParser(mytexts_grammar, trace=0)\n",
    "trees = parser.parse(text_tokens)\n",
    "for t in trees:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assume that a word that contains spell of handwritten errors is not in the base vocabulary, so \n",
    "the word with errors can by identified by not finding it in the vocabulary and after that we can use \n",
    "the minimum edit distance function to find the word/words in the base vocabulary that are the most \n",
    "similar with the word that contains mistakes and replace it with what we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 17 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    NP -> Det N [0.5]\n",
      "    NP -> NP PP [0.25]\n",
      "    NP -> 'John' [0.1]\n",
      "    NP -> 'I' [0.15]\n",
      "    Det -> 'the' [0.8]\n",
      "    Det -> 'a' [0.2]\n",
      "    N -> 'man' [0.5]\n",
      "    N -> 'telescope' [0.5]\n",
      "    VP -> VP PP [0.1]\n",
      "    VP -> V NP [0.7]\n",
      "    VP -> V [0.2]\n",
      "    V -> 'ate' [0.35]\n",
      "    V -> 'saw' [0.65]\n",
      "    PP -> P NP [1.0]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'in' [0.39]\n",
      "Inserting tokens into the most likely constituents table...\n",
      "   Insert: |=......| I\n",
      "   Insert: |.=.....| saw\n",
      "   Insert: |..=....| the\n",
      "   Insert: |...=...| man\n",
      "   Insert: |....=..| with\n",
      "   Insert: |.....=.| a\n",
      "   Insert: |......=| telescope\n",
      "Finding the most likely constituents spanning 1 text elements...\n",
      "   Insert: |=......| NP -> 'I' [0.15]               0.1500000000 \n",
      "   Insert: |.=.....| V -> 'saw' [0.65]              0.6500000000 \n",
      "   Insert: |.=.....| VP -> V [0.2]                  0.1300000000 \n",
      "   Insert: |..=....| Det -> 'the' [0.8]             0.8000000000 \n",
      "   Insert: |...=...| N -> 'man' [0.5]               0.5000000000 \n",
      "   Insert: |....=..| P -> 'with' [0.61]             0.6100000000 \n",
      "   Insert: |.....=.| Det -> 'a' [0.2]               0.2000000000 \n",
      "   Insert: |......=| N -> 'telescope' [0.5]         0.5000000000 \n",
      "Finding the most likely constituents spanning 2 text elements...\n",
      "   Insert: |==.....| S -> NP VP [1.0]               0.0195000000 \n",
      "   Insert: |..==...| NP -> Det N [0.5]              0.2000000000 \n",
      "   Insert: |.....==| NP -> Det N [0.5]              0.0500000000 \n",
      "Finding the most likely constituents spanning 3 text elements...\n",
      "   Insert: |.===...| VP -> V NP [0.7]               0.0910000000 \n",
      "   Insert: |....===| PP -> P NP [1.0]               0.0305000000 \n",
      "Finding the most likely constituents spanning 4 text elements...\n",
      "   Insert: |====...| S -> NP VP [1.0]               0.0136500000 \n",
      "Finding the most likely constituents spanning 5 text elements...\n",
      "   Insert: |..=====| NP -> NP PP [0.25]             0.0015250000 \n",
      "Finding the most likely constituents spanning 6 text elements...\n",
      "   Insert: |.======| VP -> VP PP [0.1]              0.0002775500 \n",
      "   Insert: |.======| VP -> V NP [0.7]               0.0006938750 \n",
      "  Discard: |.======| VP -> VP PP [0.1]              0.0002775500 \n",
      "Finding the most likely constituents spanning 7 text elements...\n",
      "   Insert: |=======| S -> NP VP [1.0]               0.0001040812 \n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Det the) (N man))\n",
      "      (PP (P with) (NP (Det a) (N telescope)))))) (p=0.000104081)\n"
     ]
    }
   ],
   "source": [
    "from nltk import PCFG\n",
    "pcfg1 = PCFG.fromstring(\"\"\"\n",
    "S -> NP VP [1.0]\n",
    "NP -> Det N [0.5] | NP PP [0.25] | 'John' [0.1] | 'I' [0.15]\n",
    "Det -> 'the' [0.8] | 'a' [0.2]\n",
    "N -> 'man' [0.5] | 'telescope' [0.5]\n",
    "VP -> VP PP [0.1] | V NP [0.7] | V [0.2]\n",
    "V -> 'ate' [0.35] | 'saw' [0.65]\n",
    "PP -> P NP [1.0]\n",
    "P -> 'with' [0.61] | 'in' [0.39]\n",
    "\"\"\")\n",
    "print(pcfg1)\n",
    "text = \"I saw the man with a telescope\"\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "viterbi_parser = nltk.ViterbiParser(pcfg1,trace=3)\n",
    "trees = viterbi_parser.parse(text_tokens)\n",
    "for tree in trees:\n",
    " print(tree)\n",
    " tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(S\n",
    "  (NP I)\n",
    "  (VP\n",
    "    (V saw)\n",
    "    (NP\n",
    "      (NP (Det the) (N man))\n",
    "      (PP (P with) (NP (Det a) (N telescope)))))) (p=0.000104081)\n",
    "\n",
    "\n",
    "Changing the value of trace gives us more or less information about constituents probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 17 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    NP -> Det N [0.5]\n",
      "    NP -> NP PP [0.25]\n",
      "    NP -> 'John' [0.1]\n",
      "    NP -> 'I' [0.15]\n",
      "    Det -> 'the' [0.8]\n",
      "    Det -> 'a' [0.2]\n",
      "    N -> 'man' [0.5]\n",
      "    N -> 'telescope' [0.5]\n",
      "    VP -> VP PP [0.7]\n",
      "    VP -> V NP [0.1]\n",
      "    VP -> V [0.2]\n",
      "    V -> 'ate' [0.35]\n",
      "    V -> 'saw' [0.65]\n",
      "    PP -> P NP [1.0]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'in' [0.39]\n",
      "Inserting tokens into the most likely constituents table...\n",
      "   Insert: |=......| I\n",
      "   Insert: |.=.....| saw\n",
      "   Insert: |..=....| the\n",
      "   Insert: |...=...| man\n",
      "   Insert: |....=..| with\n",
      "   Insert: |.....=.| a\n",
      "   Insert: |......=| telescope\n",
      "Finding the most likely constituents spanning 1 text elements...\n",
      "   Insert: |=......| NP -> 'I' [0.15]               0.1500000000 \n",
      "   Insert: |.=.....| V -> 'saw' [0.65]              0.6500000000 \n",
      "   Insert: |.=.....| VP -> V [0.2]                  0.1300000000 \n",
      "   Insert: |..=....| Det -> 'the' [0.8]             0.8000000000 \n",
      "   Insert: |...=...| N -> 'man' [0.5]               0.5000000000 \n",
      "   Insert: |....=..| P -> 'with' [0.61]             0.6100000000 \n",
      "   Insert: |.....=.| Det -> 'a' [0.2]               0.2000000000 \n",
      "   Insert: |......=| N -> 'telescope' [0.5]         0.5000000000 \n",
      "Finding the most likely constituents spanning 2 text elements...\n",
      "   Insert: |==.....| S -> NP VP [1.0]               0.0195000000 \n",
      "   Insert: |..==...| NP -> Det N [0.5]              0.2000000000 \n",
      "   Insert: |.....==| NP -> Det N [0.5]              0.0500000000 \n",
      "Finding the most likely constituents spanning 3 text elements...\n",
      "   Insert: |.===...| VP -> V NP [0.1]               0.0130000000 \n",
      "   Insert: |....===| PP -> P NP [1.0]               0.0305000000 \n",
      "Finding the most likely constituents spanning 4 text elements...\n",
      "   Insert: |====...| S -> NP VP [1.0]               0.0019500000 \n",
      "Finding the most likely constituents spanning 5 text elements...\n",
      "   Insert: |..=====| NP -> NP PP [0.25]             0.0015250000 \n",
      "Finding the most likely constituents spanning 6 text elements...\n",
      "   Insert: |.======| VP -> VP PP [0.7]              0.0002775500 \n",
      "  Discard: |.======| VP -> V NP [0.1]               0.0000991250 \n",
      "  Discard: |.======| VP -> V NP [0.1]               0.0000991250 \n",
      "Finding the most likely constituents spanning 7 text elements...\n",
      "   Insert: |=======| S -> NP VP [1.0]               0.0000416325 \n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det the) (N man)))\n",
      "    (PP (P with) (NP (Det a) (N telescope))))) (p=4.16325e-05)\n"
     ]
    }
   ],
   "source": [
    "pcfg1 = PCFG.fromstring(\"\"\"\n",
    "S -> NP VP [1.0]\n",
    "NP -> Det N [0.5] | NP PP [0.25] | 'John' [0.1] | 'I' [0.15]\n",
    "Det -> 'the' [0.8] | 'a' [0.2]\n",
    "N -> 'man' [0.5] | 'telescope' [0.5]\n",
    "VP -> VP PP [0.7] | V NP [0.1] | V [0.2]\n",
    "V -> 'ate' [0.35] | 'saw' [0.65]\n",
    "PP -> P NP [1.0]\n",
    "P -> 'with' [0.61] | 'in' [0.39]\n",
    "\"\"\")\n",
    "print(pcfg1)\n",
    "text = \"I saw the man with a telescope\"\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "viterbi_parser = nltk.ViterbiParser(pcfg1,trace=3)\n",
    "trees = viterbi_parser.parse(text_tokens)\n",
    "for tree in trees:\n",
    " print(tree)\n",
    " tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(S\n",
    "  (NP I)\n",
    "  (VP\n",
    "    (VP (V saw) (NP (Det the) (N man)))\n",
    "    (PP (P with) (NP (Det a) (N telescope))))) (p=4.16325e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP-SBJ -> NP , ADJP , [0.000392567]\n",
      "NP -> NNP NNP [0.0309391]\n",
      "NNP -> 'Pierre' [0.00010627]\n",
      "NNP -> 'Vinken' [0.00021254]\n",
      ", -> ',' [0.999795]\n",
      "ADJP -> NP JJ [0.014556]\n",
      "NP -> CD NNS [0.0110015]\n",
      "CD -> '61' [0.00141004]\n",
      "NNS -> 'years' [0.0190177]\n",
      "JJ -> 'old' [0.00411382]\n",
      "VP -> MD VP [0.0523088]\n",
      "MD -> 'will' [0.30205]\n",
      "VP -> VB NP PP-CLR NP-TMP [0.000137836]\n",
      "VB -> 'join' [0.00156617]\n",
      "NP -> DT NN [0.0851458]\n",
      "DT -> 'the' [0.49455]\n",
      "NN -> 'board' [0.0022786]\n",
      "PP-CLR -> IN NP [0.679445]\n",
      "IN -> 'as' [0.0337831]\n",
      "NP -> DT JJ NN [0.031192]\n",
      "DT -> 'a' [0.229516]\n",
      "JJ -> 'nonexecutive' [0.000857045]\n",
      "NN -> 'director' [0.0024305]\n",
      "NP-TMP -> NNP CD [0.0437158]\n",
      "Inserting tokens into the most likely constituents table...\n",
      "Finding the most likely constituents spanning 1 text elements...\n",
      "Finding the most likely constituents spanning 2 text elements...\n",
      "Finding the most likely constituents spanning 3 text elements...\n",
      "Finding the most likely constituents spanning 4 text elements...\n",
      "Finding the most likely constituents spanning 5 text elements...\n",
      "Finding the most likely constituents spanning 6 text elements...\n",
      "(S\n",
      "  (NP-SBJ (DT the) (NN boy))\n",
      "  (NP-PRD\n",
      "    (NP (NNS jumps))\n",
      "    (PP (IN over) (NP (DT the) (NN board))))) (p=1.25001e-20)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "productions=[]\n",
    "S=nltk.Nonterminal('S')\n",
    "for f in treebank.fileids():\n",
    "    for tree in treebank.parsed_sents(f):\n",
    "        productions+=tree.productions()\n",
    "\n",
    "grammar=nltk.induce_pcfg(S,productions)\n",
    "\n",
    "for p in grammar.productions()[1:25]:\n",
    "    print(p)\n",
    "myparser = nltk.ViterbiParser(grammar,1)\n",
    "text = \"the boy jumps over the board\"\n",
    "mytokens = nltk.word_tokenize(text)\n",
    "myparsing, = myparser.parse(mytokens)\n",
    "print(myparsing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(S\n",
    "  (NP-SBJ (DT the) (NN boy))\n",
    "  (NP-PRD\n",
    "    (NP (NNS jumps))\n",
    "    (PP (IN over) (NP (DT the) (NN board))))) (p=1.25001e-20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
